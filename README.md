# vladimir-tts-studio

`vladimir-tts-studio` — локальный проект для создания собственного TTS-голоса на базе Piper. Репозиторий объединяет полный цикл работы с голосовой моделью: подготовку текстов и структуры проекта, запись и валидацию аудио, обучение модели, экспорт в ONNX и офлайн-синтез готового голоса.

## Windows (Training) — Quick Start

### Требуется установить (один раз)

- Git (`git --version`)
- Python 3.11+ (лучше 3.12)
- espeak-ng (обязательно): `espeak-ng --version`
- Visual Studio 2022 Build Tools → workload **Desktop development with C++** (нужно для сборки monotonic_align)

> Важно: в Windows часто `python` — это алиас из WindowsApps. В командах ниже используйте python из `.venv`.

### Шаги (после клона репозитория)

**1) Создать venv и поставить зависимости (PowerShell в корне репо):**
```powershell
py -3.12 -m venv .venv
.\.venv\Scripts\Activate.ps1
python -m pip install -U pip setuptools wheel
python -m pip install -r requirements\train.txt
python -m pip install -e .
```

Проект ориентирован на полностью локальный сценарий без обязательных облачных сервисов. Основная идея — дать воспроизводимый и прозрачный пайплайн, в котором все этапы от исходного текста до итоговой модели находятся под контролем пользователя. Внутри репозитория есть CLI-приложение, инструменты подготовки датасета, проверка качества манифеста и аудио, интеграция с обучающим контуром Piper и отдельный веб-интерфейс студии записи.

Архитектурно проект разделён на несколько слоёв. Модуль `app` предоставляет пользовательские workflow-команды (подготовка, запись, обучение, экспорт, проверка окружения), модуль `dataset` отвечает за очистку текста, сегментацию и работу с манифестом, а модуль `training` инкапсулирует запуск обучения, preflight-проверки и экспорт артефактов модели. Веб-часть студии записи находится в `studio/web` и работает как локальный интерфейс для сбора голосовых данных.

Для обучения ожидается стандартная структура проекта с `metadata/train.csv` и WAV-файлами, а также корректное окружение с зависимостями синтеза и тренировки. Валидация перед запуском обучения проверяет импортируемость ключевых модулей, наличие данных, целостность путей в манифесте и базовые аудио-параметры. Это снижает риск типичных ошибок, когда запуск обучения завершается из-за неконсистентного датасета или неподготовленной среды.

Итогом работы `vladimir-tts-studio` является обученная голосовая модель, пригодная для дальнейшего экспорта и использования в inference-сценариях. Репозиторий подходит как для персональных экспериментов с клонированием голоса, так и для регулярной итеративной дообучаемой разработки, где важно последовательно улучшать качество датасета и звучание модели.
